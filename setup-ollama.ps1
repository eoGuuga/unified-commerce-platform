# ============================================
# CONFIGURA√á√ÉO DO OLLAMA - IA PARA WHATSAPP
# ============================================

Write-Host "ü§ñ CONFIGURANDO OLLAMA PARA WHATSAPP BOT" -ForegroundColor Magenta
Write-Host "=========================================" -ForegroundColor Magenta
Write-Host ""

# Verificar se Ollama j√° est√° instalado
Write-Host "üîç Verificando se Ollama est√° instalado..." -ForegroundColor Yellow
try {
    $ollamaVersion = ollama --version 2>$null
    if ($LASTEXITCODE -eq 0) {
        Write-Host "‚úÖ Ollama j√° instalado: $ollamaVersion" -ForegroundColor Green
    } else {
        throw "Ollama n√£o encontrado"
    }
} catch {
    Write-Host "‚ùå Ollama n√£o encontrado. Instalando..." -ForegroundColor Yellow

    # Baixar e instalar Ollama
    try {
        Write-Host "   Baixando Ollama..." -ForegroundColor Gray
        Invoke-WebRequest -Uri "https://ollama.ai/download/OllamaSetup.exe" -OutFile "$env:TEMP\OllamaSetup.exe"

        Write-Host "   Instalando Ollama..." -ForegroundColor Gray
        Start-Process -FilePath "$env:TEMP\OllamaSetup.exe" -ArgumentList "/S" -Wait

        # Aguardar instala√ß√£o
        Start-Sleep -Seconds 10

        # Verificar novamente
        $ollamaVersion = ollama --version 2>$null
        if ($LASTEXITCODE -eq 0) {
            Write-Host "‚úÖ Ollama instalado com sucesso!" -ForegroundColor Green
        } else {
            Write-Host "‚ùå Falha na instala√ß√£o do Ollama" -ForegroundColor Red
            Write-Host "   Instale manualmente: https://ollama.ai/download" -ForegroundColor Yellow
            exit 1
        }
    } catch {
        Write-Host "‚ùå Erro ao instalar Ollama: $($_.Exception.Message)" -ForegroundColor Red
        Write-Host "   Instale manualmente: https://ollama.ai/download" -ForegroundColor Yellow
        exit 1
    }
}

Write-Host ""

# Verificar se servi√ßo Ollama est√° rodando
Write-Host "üîç Verificando servi√ßo Ollama..." -ForegroundColor Yellow
try {
    $response = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -Method GET -TimeoutSec 5
    if ($response.StatusCode -eq 200) {
        Write-Host "‚úÖ Servi√ßo Ollama rodando" -ForegroundColor Green
    } else {
        throw "Servi√ßo n√£o responde"
    }
} catch {
    Write-Host "‚ö†Ô∏è  Servi√ßo Ollama n√£o est√° rodando. Iniciando..." -ForegroundColor Yellow

    try {
        Start-Process -FilePath "ollama" -ArgumentList "serve" -NoNewWindow
        Start-Sleep -Seconds 5

        # Testar novamente
        $response = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -Method GET -TimeoutSec 5
        if ($response.StatusCode -eq 200) {
            Write-Host "‚úÖ Servi√ßo Ollama iniciado!" -ForegroundColor Green
        } else {
            throw "Servi√ßo n√£o iniciou"
        }
    } catch {
        Write-Host "‚ùå Falha ao iniciar servi√ßo Ollama" -ForegroundColor Red
        Write-Host "   Inicie manualmente: ollama serve" -ForegroundColor Yellow
    }
}

Write-Host ""

# Baixar modelo Llama 2 (mais leve e eficiente)
Write-Host "üì• Baixando modelo Llama 2..." -ForegroundColor Yellow
Write-Host "   Este modelo √© otimizado para conversas em portugu√™s" -ForegroundColor Gray
Write-Host "   Tamanho aproximado: 3.8GB (pode demorar)" -ForegroundColor Gray
Write-Host ""

try {
    # Verificar se modelo j√° existe
    $models = Invoke-WebRequest -Uri "http://localhost:11434/api/tags" -Method GET | ConvertFrom-Json
    $hasLlama2 = $models.models | Where-Object { $_.name -like "*llama2*" }

    if ($hasLlama2) {
        Write-Host "‚úÖ Modelo Llama 2 j√° baixado!" -ForegroundColor Green
    } else {
        Write-Host "   Baixando llama2:7b (pode demorar alguns minutos)..." -ForegroundColor Gray
        ollama pull llama2:7b

        if ($LASTEXITCODE -eq 0) {
            Write-Host "‚úÖ Modelo Llama 2 baixado com sucesso!" -ForegroundColor Green
        } else {
            Write-Host "‚ùå Erro ao baixar modelo Llama 2" -ForegroundColor Red
            Write-Host "   Execute manualmente: ollama pull llama2:7b" -ForegroundColor Yellow
        }
    }
} catch {
    Write-Host "‚ùå Erro ao verificar/baixar modelo: $($_.Exception.Message)" -ForegroundColor Red
}

Write-Host ""

# Configurar vari√°veis de ambiente no backend
Write-Host "‚öôÔ∏è  Configurando backend..." -ForegroundColor Yellow

$envPath = "backend/.env"
$ollamaConfig = "OLLAMA_URL=http://localhost:11434"

if (Test-Path $envPath) {
    $envContent = Get-Content $envPath -Raw

    if ($envContent -notmatch "OLLAMA_URL") {
        Add-Content -Path $envPath -Value "`n# IA - Ollama`n$ollamaConfig"
        Write-Host "‚úÖ OLLAMA_URL adicionado ao .env" -ForegroundColor Green
    } else {
        Write-Host "‚úÖ OLLAMA_URL j√° configurado" -ForegroundColor Green
    }
} else {
    Write-Host "‚ùå Arquivo backend/.env n√£o encontrado" -ForegroundColor Red
    Write-Host "   Crie o arquivo primeiro" -ForegroundColor Yellow
}

Write-Host ""

# Testar integra√ß√£o
Write-Host "üß™ Testando integra√ß√£o..." -ForegroundColor Yellow

try {
    $testPrompt = @{
        model = "llama2:7b"
        prompt = "Ol√°! Voc√™ √© um assistente de vendas de chocolates. Responda apenas: 'Ol√°! Como posso ajudar voc√™ hoje?'"
        stream = $false
    } | ConvertTo-Json

    $response = Invoke-WebRequest -Uri "http://localhost:11434/api/generate" -Method POST -Body $testPrompt -ContentType "application/json" -TimeoutSec 30

    if ($response.StatusCode -eq 200) {
        $result = $response.Content | ConvertFrom-Json
        Write-Host "‚úÖ Integra√ß√£o Ollama funcionando!" -ForegroundColor Green
        Write-Host "   Resposta de teste: $($result.response)" -ForegroundColor Gray
    } else {
        throw "Status code: $($response.StatusCode)"
    }
} catch {
    Write-Host "‚ùå Falha no teste de integra√ß√£o: $($_.Exception.Message)" -ForegroundColor Red
    Write-Host "   Verifique se o Ollama est√° rodando corretamente" -ForegroundColor Yellow
}

Write-Host ""

# Resultado final
Write-Host "üéØ CONFIGURA√á√ÉO CONCLU√çDA!" -ForegroundColor Green
Write-Host "==========================" -ForegroundColor Green
Write-Host ""
Write-Host "‚úÖ O que foi configurado:" -ForegroundColor White
Write-Host "   ‚Ä¢ Ollama instalado e rodando" -ForegroundColor White
Write-Host "   ‚Ä¢ Modelo Llama 2 baixado" -ForegroundColor White
Write-Host "   ‚Ä¢ Backend configurado" -ForegroundColor White
Write-Host "   ‚Ä¢ Integra√ß√£o testada" -ForegroundColor White
Write-Host ""
Write-Host "üöÄ PR√ìXIMOS PASSOS:" -ForegroundColor Cyan
Write-Host "   1. Inicie o backend: cd backend && npm run start:dev" -ForegroundColor White
Write-Host "   2. Teste o WhatsApp bot" -ForegroundColor White
Write-Host "   3. Envie mensagens para ver a IA em a√ß√£o!" -ForegroundColor White
Write-Host ""
Write-Host "üìö PARA SUPORTE:" -ForegroundColor Gray
Write-Host "   ‚Ä¢ Documenta√ß√£o: https://github.com/jmorganca/ollama" -ForegroundColor Gray
Write-Host "   ‚Ä¢ Modelos dispon√≠veis: ollama list" -ForegroundColor Gray
Write-Host ""
Write-Host "ü§ñ SEU WHATSAPP BOT AGORA TEM IA!" -ForegroundColor Magenta